# -*- coding: utf-8 -*-
"""casting.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PtXH7uNScsgWa4AvQ4KHMfMPK5byz1g3
"""

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import categorical_crossentropy
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import confusion_matrix
from keras.layers import AveragePooling2D
from sklearn import metrics
import itertools
import os
import shutil
import random
import glob
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/gdrive')

train_path = '/content/gdrive/MyDrive/NN/casting_512x512/train'
valid_path = '/content/gdrive/MyDrive/NN/casting_512x512/validation'
test_path = '/content/gdrive/MyDrive/NN/casting_512x512/test'

train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \
    .flow_from_directory(directory=train_path,target_size=(224,224),classes=['def_front','ok_front'], batch_size=900)
valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \
    .flow_from_directory(directory=valid_path,target_size=(224,224),classes=['def_front','ok_front'], batch_size=175)
test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \
    .flow_from_directory(directory=test_path,target_size=(224,224),classes=['def_front','ok_front'], batch_size=300)

train_imgs, train_labels = next(train_batches)
test_imgs,test_labels=next(test_batches)
valid_imgs,valid_labels=next(valid_batches)

train_labels

train_label=[]
for i in train_labels:
  train_label.append(int(i[1]))

train_label

test_labels

test_label=[]
for i in test_labels:
  test_label.append(int(i[1]))

test_label

valid_labels

valid_label=[]
for i in valid_labels:
  valid_label.append(int(i[1]))

valid_label

train_imgs = np.array(train_imgs)
train_label = np.array(train_label)
test_imgs = np.array(test_imgs)
test_label = np.array(test_label)
valid_imgs = np.array(valid_imgs)
valid_label = np.array(valid_label)

print(train_imgs.shape)
print(train_label.shape)
print(test_imgs.shape)
print(test_label.shape)
print(valid_imgs.shape)
print(valid_label.shape)

plt.figure(figsize=(8,8))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_imgs[i], cmap=plt.cm.binary)
    plt.xlabel([train_label[i]])
plt.show()

model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224,224,3)),
    tf.keras.layers.Dense(500, activation='relu'),
    tf.keras.layers.Dense(500, activation='relu'),
    tf.keras.layers.Dense(500, activation='relu'),
    tf.keras.layers.Dense(500, activation='relu'),
    tf.keras.layers.Dense(500, activation='relu'),
    tf.keras.layers.Dense(500, activation='relu'),
    tf.keras.layers.Dense(2,activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

model.fit(train_imgs, train_label,validation_data=(valid_imgs, valid_label) , epochs=10)

results1 = model.evaluate(test_imgs, test_label)
print("loss",results1[0])
print("accuracy",results1[1])

valid_label

probability_model = tf.keras.Sequential([model,tf.keras.layers.Softmax()])

predictions = probability_model.predict(test_imgs)

predictions[0]

np.argmax(predictions[0])

test_label[0]

plt.figure(figsize=(8,8))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(test_imgs[i], cmap=plt.cm.binary)
    plt.xlabel([np.argmax(predictions[i])])
plt.show()

plt.figure(figsize=(8,8))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(test_imgs[i], cmap=plt.cm.binary)
    plt.xlabel([test_label[i]])
plt.show()

from keras import regularizers
l2_model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224, 224,3)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l2(0.0001)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l2(0.0001)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l2(0.0001)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l2(0.0001)),
    tf.keras.layers.Dense(2,activation='softmax',kernel_regularizer=regularizers.l2(0.0001))
])

l2_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

l2_model.fit(train_imgs, train_label,validation_data=(valid_imgs, valid_label) , epochs=10)

l2_results = l2_model.evaluate(test_imgs, test_label)
print("loss",l2_results[0])
print("accuracy",l2_results[1])

l1_model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224, 224,3)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l1(0.0001)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l1(0.0001)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l1(0.0001)),
    tf.keras.layers.Dense(500, activation='relu',kernel_regularizer=regularizers.l1(0.0001)),
    tf.keras.layers.Dense(2,activation='softmax',kernel_regularizer=regularizers.l1(0.0001))
])

l1_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

l1_model.fit(train_imgs, train_label,validation_data=(valid_imgs, valid_label) , epochs=10)

l1_results = l1_model.evaluate(test_imgs, test_label)
print("loss",l1_results[0])
print("accuracy",l1_results[1])

valid_label

from keras.layers.core import Dropout
d_model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(224, 224,3)),
    tf.keras.layers.Dense(500, activation='relu'),Dropout(0.25),
    tf.keras.layers.Dense(500, activation='relu'),Dropout(0.25),
    tf.keras.layers.Dense(500, activation='relu'),Dropout(0.25),
    tf.keras.layers.Dense(500, activation='relu'),Dropout(0.25),
    tf.keras.layers.Dense(2,activation='softmax')
])

d_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

d_model.fit(train_imgs, train_label,validation_data=(valid_imgs, valid_label) , epochs=10)

d_results = d_model.evaluate(test_imgs, test_label)
print("loss",d_results[0])
print("accuracy",d_results[1])

list1=[results1[1],l2_results[1],l1_results[1],d_results[1]]
label1=["normal","L2","L1","Dropout"]
plt.bar(label1, list1, color ='maroon')


plt.xlabel("Labels")
plt.ylabel("Accuracy")
plt.title("Accuracy of regularization")
plt.show()

results1

cnn_model=Sequential([
                      Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),
                      MaxPool2D(pool_size=(2,2),strides=2),

                      Conv2D(64,(3,3),activation='relu'),
                      MaxPool2D(pool_size=(2,2),strides=2),

                      Flatten(),
                      Dense(500,activation='relu'),
                      Dense(500,activation='relu'),
                      Dense(2,activation='softmax')
])

cnn_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])

cnn_model.fit(train_imgs, train_label,validation_data=(valid_imgs, valid_label) , epochs=10)

cnn_results = cnn_model.evaluate(test_imgs, test_label)
print("loss",cnn_results[0])
print("accuracy",cnn_results[1])

cnn_probability_model = tf.keras.Sequential([cnn_model,tf.keras.layers.Softmax()])
cnn_predictions = cnn_probability_model.predict(test_imgs)



plt.figure(figsize=(8,8))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(test_imgs[i], cmap=plt.cm.binary)
    plt.xlabel([np.argmax(cnn_predictions[i])])
plt.show()



cnn_model2=Sequential([
                      Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),
                      MaxPool2D(pool_size=(2,2),strides=2),

                      Conv2D(64,(3,3),activation='relu'),
                      MaxPool2D(pool_size=(2,2),strides=2),

                      Conv2D(128,(3,3),activation='relu'),
                      MaxPool2D(pool_size=(2,2),strides=2),

                      Conv2D(256,(3,3),activation='relu'),
                      MaxPool2D(pool_size=(2,2),strides=2),

                      Flatten(),
                      Dense(500,activation='relu'),
                      Dense(500,activation='relu'),
                      Dense(2,activation='softmax')
])

cnn_model2.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(),
              metrics=['accuracy'])







cnn=cnn_model2.fit(train_imgs, train_label,validation_data=(valid_imgs, valid_label) , epochs=10)

cnn_results2 = cnn_model2.evaluate(test_imgs, test_label)
print("loss",cnn_results2[0])
print("accuracy",cnn_results2[1])

cnn_probability_model2 = tf.keras.Sequential([cnn_model2,tf.keras.layers.Softmax()])
cnn_predictions2 = cnn_probability_model2.predict(test_imgs)

#predicted output
plt.figure(figsize=(8,8))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(test_imgs[i], cmap=plt.cm.binary)
    plt.xlabel([np.argmax(cnn_predictions2[i])])
plt.show()

#actual output
plt.figure(figsize=(8,8))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(test_imgs[i], cmap=plt.cm.binary)
    plt.xlabel([test_label[i]])
plt.show()

import keras
from matplotlib import pyplot as plt
plt.plot(cnn.history['accuracy'])
plt.plot(cnn.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

list1=[results1[1],l2_results[1],l1_results[1],d_results[1]]
label1=["normal","L2","L1","Dropout"]
plt.bar(label1, list1, color ='maroon')


plt.xlabel("Labels")
plt.ylabel("Accuracy")
plt.title("Accuracy of regularization")
plt.show()

